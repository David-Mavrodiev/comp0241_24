{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Our Data\n",
    "\n",
    "### 1. Download it from OneDrive using this [link](https://liveuclac-my.sharepoint.com/:f:/g/personal/ucabdsm_ucl_ac_uk/Ek8oM7sBaJhFs5Py5FPdtYEB_YW0TcEVvtjjdtNqp_Ud4A?e=Alw6kD). \n",
    "### 2. Move the 'comp0241_data.zip' file into the same directory as the current notebook and unzip it.\n",
    "### 3. Make sure you have the 'comp0241_data' folder in this directory.\n",
    "### 4. Run the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "##  Extract the Astronomical Object from Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Implement at Least Two Methods for AO Extraction\n",
    "### b) Combine Methods for Improved Accuracy\n",
    "### c) Evaluate Performance with ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "def align_images_multiple_references(reference_image_paths, distorted_image_path):\n",
    "    # Load the distorted image\n",
    "    dist_img = cv2.imread(distorted_image_path)\n",
    "    dist_gray = cv2.cvtColor(dist_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Aggregate keypoints and descriptors from all reference images\n",
    "    ref_keypoints = []\n",
    "    ref_descriptors = []\n",
    "    for ref_path in reference_image_paths:\n",
    "        ref_img = cv2.imread(ref_path)\n",
    "        ref_gray = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)\n",
    "        keypoints, descriptors = sift.detectAndCompute(ref_gray, None)\n",
    "        ref_keypoints.extend(keypoints)\n",
    "        if descriptors is not None:\n",
    "            if len(ref_descriptors) == 0:\n",
    "                ref_descriptors = descriptors\n",
    "            else:\n",
    "                ref_descriptors = np.vstack((ref_descriptors, descriptors))\n",
    "\n",
    "    # Detect keypoints and descriptors in the distorted image\n",
    "    keypoints_dist, descriptors_dist = sift.detectAndCompute(dist_gray, None)\n",
    "\n",
    "    # Match features using BFMatcher\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(ref_descriptors, descriptors_dist)\n",
    "\n",
    "    # Sort matches by distance\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Extract matched keypoints\n",
    "    ref_pts = np.float32([ref_keypoints[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dist_pts = np.float32([keypoints_dist[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Estimate homography\n",
    "    matrix, mask = cv2.findHomography(dist_pts, ref_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # Warp the distorted image\n",
    "    h, w = dist_img.shape[:2]\n",
    "    aligned_image = cv2.warpPerspective(dist_img, matrix, (w, h))\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Distorted Image\")\n",
    "    plt.imshow(cv2.cvtColor(dist_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Aligned Image\")\n",
    "    plt.imshow(cv2.cvtColor(aligned_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def transform_image_with_homography(image_path, homography_matrix):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    h, w = image.shape[:2]  # Get the size from the image itself\n",
    "\n",
    "    # Apply the homography transformation\n",
    "    transformed_image = cv2.warpPerspective(image, homography_matrix, (w, h))\n",
    "\n",
    "    return transformed_image\n",
    "\n",
    "def reverse_transform_image_with_homography(transformed_image, homography_matrix):\n",
    "    \"\"\"\n",
    "    Reverse the homography transformation on an image.\n",
    "\n",
    "    Parameters:\n",
    "        transformed_image: The image that was transformed.\n",
    "        homography_matrix: The homography matrix used for the forward transformation.\n",
    "\n",
    "    Returns:\n",
    "        The reversed (original) image.\n",
    "    \"\"\"\n",
    "    # Calculate the inverse of the homography matrix\n",
    "    inverse_homography_matrix = np.linalg.inv(homography_matrix)\n",
    "    \n",
    "    # Get the size of the transformed image\n",
    "    h, w = transformed_image.shape[:2]\n",
    "    \n",
    "    # Apply the inverse homography transformation\n",
    "    original_image = cv2.warpPerspective(transformed_image, inverse_homography_matrix, (w, h))\n",
    "    \n",
    "    return original_image\n",
    "\n",
    "def save_homography_matrix(matrix, file_path):\n",
    "    # Convert the NumPy array to a list for JSON serialization\n",
    "    matrix_list = matrix.tolist()\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(matrix_list, f)\n",
    "\n",
    "def process_dataset_images(dataset_folder):\n",
    "    images_folder = os.path.join(dataset_folder, \"images\")\n",
    "    \n",
    "    for image_name in os.listdir(images_folder):\n",
    "        print(image_name)\n",
    "        image_path = os.path.join(images_folder, image_name)\n",
    "\n",
    "        reference_image_paths = [\n",
    "            './Dataset 2/images/000003.png', './Dataset 2/images/000010.png', './Dataset 2/images/000016.png', './Dataset 2/images/000021.png', './Dataset 2/images/000022.png', './Dataset 2/images/000028.png', './Dataset 2/images/000030.png', './Dataset 2/images/000033.png', './Dataset 2/images/000046.png', './Dataset 2/images/000051.png', './Dataset 2/images/000053.png', './Dataset 2/images/000060.png', './Dataset 2/images/000061.png', './Dataset 2/images/000064.png',\n",
    "            './Dataset 2/images/000072.png', './Dataset 2/images/000081.png', './Dataset 2/images/000096.png', \n",
    "        ]  # Add more references\n",
    "        #distorted_image_path = './Dataset 2/images/000083.png'\n",
    "        homography_matrix = align_images_multiple_references(reference_image_paths, image_path)\n",
    "\n",
    "        # Transform the image\n",
    "        transformed_image = transform_image_with_homography(image_path, homography_matrix)\n",
    "\n",
    "        if not cv2.imwrite(f\"./calibrated-images/{image_name}\", transformed_image):\n",
    "            print(f\"Failed to save image: {image_name}\")\n",
    "\n",
    "        save_homography_matrix(homography_matrix, f\"./calibrated-images/{image_name.replace('png', 'json')}\")\n",
    "\n",
    "        # Plot the original and transformed images\n",
    "        #original_image = cv2.imread(image_path)\n",
    "        #plt.figure(figsize=(12, 6))\n",
    "        #plt.subplot(1, 2, 1)\n",
    "        #plt.title(\"Original Image\")\n",
    "        #plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "        #plt.axis(\"off\")\n",
    "\n",
    "        #plt.subplot(1, 2, 2)\n",
    "        #plt.title(\"Transformed Image\")\n",
    "        #plt.imshow(cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "        #plt.axis(\"off\")\n",
    "\n",
    "        #plt.tight_layout()\n",
    "        #plt.show()\n",
    "\n",
    "# Example usage\n",
    "dataset_folder = './Dataset 2'  # Replace with the actual dataset folder\n",
    "process_dataset_images(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_homography_matrix(file_path):\n",
    "    # Load the JSON file and convert the list back to a NumPy array\n",
    "    with open(file_path, 'r') as f:\n",
    "        matrix_list = json.load(f)\n",
    "    return np.array(matrix_list)\n",
    "\n",
    "def reverse_transform_image_with_homography(transformed_image, homography_matrix):\n",
    "    \"\"\"\n",
    "    Reverse the homography transformation on an image.\n",
    "\n",
    "    Parameters:\n",
    "        transformed_image: The image that was transformed.\n",
    "        homography_matrix: The homography matrix used for the forward transformation.\n",
    "\n",
    "    Returns:\n",
    "        The reversed (original) image.\n",
    "    \"\"\"\n",
    "    # Calculate the inverse of the homography matrix\n",
    "    inverse_homography_matrix = np.linalg.inv(homography_matrix)\n",
    "    \n",
    "    # Get the size of the transformed image\n",
    "    h, w = transformed_image.shape[:2]\n",
    "    \n",
    "    # Apply the inverse homography transformation\n",
    "    original_image = cv2.warpPerspective(transformed_image, inverse_homography_matrix, (w, h))\n",
    "    \n",
    "    return original_image\n",
    "\n",
    "def color_thresholding(image, lower_bounds, upper_bounds):\n",
    "    \"\"\"\n",
    "    Perform color thresholding to segment the globe.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image in BGR format.\n",
    "        lower_bounds (list of numpy.ndarray): List of lower HSV color bounds.\n",
    "        upper_bounds (list of numpy.ndarray): List of upper HSV color bounds.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Binary mask highlighting the selected colors.\n",
    "    \"\"\"\n",
    "    # Convert image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = np.zeros(hsv_image.shape[:2], dtype=np.uint8)\n",
    "    # Apply each color threshold and combine the masks\n",
    "    for lower_bound, upper_bound in zip(lower_bounds, upper_bounds):\n",
    "        mask |= cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    return mask\n",
    "\n",
    "def refined_circle_detection_with_mask(image, color_mask):\n",
    "    \"\"\"\n",
    "    Detect a single circular shape in the image using a color mask to focus the detection.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image in BGR format.\n",
    "        color_mask (numpy.ndarray): Binary mask obtained from color thresholding.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Binary mask with the detected circle.\n",
    "    \"\"\"\n",
    "    # Apply the mask to the image\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=color_mask)\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (9, 9), 2)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(blurred_image, cmap='gray')\n",
    "    plt.title(f\"Thresholding Result {i:06d}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    # Detect circles using HoughCircles with adjusted parameters\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred_image,\n",
    "        cv2.HOUGH_GRADIENT,\n",
    "        dp=0.2,\n",
    "        minDist=200,\n",
    "        param1=150,\n",
    "        param2=40,\n",
    "        minRadius=30,\n",
    "        maxRadius=400,\n",
    "    )\n",
    "\n",
    "    # Create a binary mask with the same dimensions as the input image\n",
    "    mask = np.zeros_like(gray_image)\n",
    "    if circles is not None:\n",
    "        # Get the first (most prominent) circle\n",
    "        circle = np.round(circles[0, 0]).astype(\"int\")\n",
    "        x, y, r = circle\n",
    "        # Draw the circle on the mask\n",
    "        cv2.circle(mask, (x, y), r, 255, -1)\n",
    "    return mask\n",
    "\n",
    "def compute_roc_curve(predicted_mask, ground_truth_mask):\n",
    "    \"\"\"\n",
    "    Compute ROC curve and AUC for a predicted mask and ground truth mask.\n",
    "\n",
    "    Parameters:\n",
    "        predicted_mask (numpy.ndarray): Predicted binary mask.\n",
    "        ground_truth_mask (numpy.ndarray): Ground truth binary mask.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (fpr, tpr, roc_auc) False Positive Rate, True Positive Rate, and Area Under Curve.\n",
    "    \"\"\"\n",
    "    # Binarize the masks\n",
    "    predicted_binary = (predicted_mask > 0).astype(np.uint8).flatten()\n",
    "    ground_truth_binary = (ground_truth_mask > 0).astype(np.uint8).flatten()\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, _ = roc_curve(ground_truth_binary, predicted_binary)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "# Dataset paths\n",
    "images_folder = './Dataset 2/images/'\n",
    "corrected_images_folder = './calibrated-images/'\n",
    "masks_folder = './Dataset 2/masks/'\n",
    "\n",
    "# Bounds for color thresholding\n",
    "lower_bounds = [\n",
    "    np.array([100, 50, 50]),  # Lower bound of blue in HSV\n",
    "    np.array([0, 0, 200]),    # Lower bound of white in HSV\n",
    "]\n",
    "upper_bounds = [\n",
    "    np.array([140, 255, 255]),  # Upper bound of blue in HSV\n",
    "    np.array([180, 50, 255]),   # Upper bound of white in HSV\n",
    "]\n",
    "\n",
    "# Lists to store ROC values\n",
    "all_fpr = []\n",
    "all_tpr = []\n",
    "all_auc = []\n",
    "\n",
    "# Loop through all images and masks\n",
    "for i in range(100):\n",
    "    image_path = os.path.join(images_folder, f\"{i:06d}.png\")\n",
    "    corrected_image_path = os.path.join(corrected_images_folder, f\"{i:06d}.png\")\n",
    "    mask_path = os.path.join(masks_folder, f\"{i:06d}.png\")\n",
    "\n",
    "    # Read image and ground truth mask\n",
    "    image = cv2.imread(image_path)\n",
    "    corrected_image = cv2.imread(corrected_image_path)\n",
    "    ground_truth_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    loaded_matrix = load_homography_matrix(corrected_image_path.replace(\"png\", \"json\"))\n",
    "\n",
    "    # Generate color mask\n",
    "    color_mask = color_thresholding(corrected_image, lower_bounds, upper_bounds)\n",
    "\n",
    "    # Plot the thresholding result\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(color_mask, cmap='gray')\n",
    "    plt.title(f\"Thresholding Result {i:06d}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # Refine circle detection with color mask\n",
    "    predicted_mask = reverse_transform_image_with_homography(refined_circle_detection_with_mask(image, color_mask), loaded_matrix)\n",
    "\n",
    "    if not cv2.imwrite(f\"./calibrated-images/{i:06d}_predicted_mask.png\", predicted_mask):\n",
    "            print(f\"Failed to save {i:06d}_predicted_mask.png\")\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, roc_auc = compute_roc_curve(predicted_mask, ground_truth_mask)\n",
    "\n",
    "    # Store the results\n",
    "    all_fpr.append(fpr)\n",
    "    all_tpr.append(tpr)\n",
    "    all_auc.append(roc_auc)\n",
    "\n",
    "    # Plot image, ground truth mask, and predicted mask\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Image {i:06d}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(ground_truth_mask, cmap='gray')\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(predicted_mask, cmap='gray')\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compute average ROC curve (mean TPR for each FPR)\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.zeros_like(mean_fpr)\n",
    "for fpr, tpr in zip(all_fpr, all_tpr):\n",
    "    mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "mean_tpr /= len(all_tpr)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "# Plot average ROC curve\n",
    "plt.figure()\n",
    "plt.plot(mean_fpr, mean_tpr, label=f\"Mean ROC (AUC = {mean_auc:.2f})\")\n",
    "plt.title(\"Average ROC Curve for Test Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Print mean AUC\n",
    "print(f\"Mean AUC: {mean_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "## Measure the Projection Point of the Rotation Axis and the Height of the AO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Determine the Geometric Centre in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Dataset paths\n",
    "images_folder = './Dataset 2/images/'\n",
    "masks_folder = './calibrated-images/'\n",
    "\n",
    "def find_mask_center(mask):\n",
    "    # Compute the coordinates of the white pixels\n",
    "    white_pixels = np.column_stack(np.where(mask == 255))\n",
    "\n",
    "    if len(white_pixels) == 0:\n",
    "        print(f\"No white pixels found in mask for index {i}, skipping.\")\n",
    "        return None, None\n",
    "\n",
    "    # Compute the mean (center location) of the white pixels\n",
    "    center_y, center_x = white_pixels.mean(axis=0)\n",
    "    return center_x, center_y\n",
    "\n",
    "for i in range(100):\n",
    "    image_path = os.path.join(images_folder, f\"{i:06d}.png\")\n",
    "    mask_path = os.path.join(masks_folder, f\"{i:06d}_predicted_mask.png\")\n",
    "\n",
    "    # Read image and predicted mask\n",
    "    image = cv2.imread(image_path)\n",
    "    predicted_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is None or predicted_mask is None:\n",
    "        print(f\"Missing image or mask for index {i}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    center_x, center_y = find_mask_center(predicted_mask)\n",
    "\n",
    "    # Plot image and predicted mask\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    # Plot the original image with the center marked\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.scatter([center_x], [center_y], color='red', s=40, label='Center')\n",
    "    plt.title(\"Original Image with Center\")\n",
    "    plt.legend()\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plot the predicted mask\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(predicted_mask, cmap='gray')\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Assess the Movement of the Centre Over Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to the video\n",
    "video_path = './single_rotation_top_view.mp4'\n",
    "\n",
    "# Open the video file\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video was successfully opened\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_rate = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "max_images = 100  # Maximum number of frames to process\n",
    "interval = max(1, total_frames // max_images)  # Interval to skip frames\n",
    "\n",
    "print(f\"Total frames: {total_frames}, Processing every {interval}th frame.\")\n",
    "\n",
    "# Initialize variables\n",
    "frame_count = 0\n",
    "processed_count = 0\n",
    "all_centers = []\n",
    "first_frame = None\n",
    "\n",
    "# Lower and upper bounds for color thresholding\n",
    "lower_bounds = [\n",
    "    np.array([10, 0, 0]),  # Example for specific hue\n",
    "    np.array([0, 0, 200])  # Bright whites\n",
    "]\n",
    "upper_bounds = [\n",
    "    np.array([150, 250, 200]),  # Saturated color range\n",
    "    np.array([180, 50, 255])    # Bright whites\n",
    "]\n",
    "\n",
    "# Helper functions\n",
    "def color_thresholding(image, lower_bounds, upper_bounds):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = np.zeros(hsv_image.shape[:2], dtype=np.uint8)\n",
    "    for lower_bound, upper_bound in zip(lower_bounds, upper_bounds):\n",
    "        mask |= cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    return mask\n",
    "\n",
    "def refined_circle_detection_with_mask(image, color_mask):\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=color_mask)\n",
    "    gray_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (9, 9), 2)\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred_image,\n",
    "        cv2.HOUGH_GRADIENT,\n",
    "        dp=0.2,\n",
    "        minDist=200,\n",
    "        param1=150,\n",
    "        param2=40,\n",
    "        minRadius=30,\n",
    "        maxRadius=400,\n",
    "    )\n",
    "    mask = np.zeros_like(gray_image)\n",
    "    if circles is not None:\n",
    "        circle = np.round(circles[0, 0]).astype(\"int\")\n",
    "        x, y, r = circle\n",
    "        cv2.circle(mask, (x, y), r, 255, -1)\n",
    "    return mask\n",
    "\n",
    "def find_mask_center(binary_mask):\n",
    "    moments = cv2.moments(binary_mask)\n",
    "    if moments[\"m00\"] != 0:\n",
    "        center_x = int(moments[\"m10\"] / moments[\"m00\"])\n",
    "        center_y = int(moments[\"m01\"] / moments[\"m00\"])\n",
    "        return center_x, center_y\n",
    "    return None\n",
    "\n",
    "# Process the video frame by frame\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break  # Break if no more frames\n",
    "\n",
    "    if frame_count % interval == 0:\n",
    "        # Store the first frame for visualization\n",
    "        if processed_count == 0:\n",
    "            first_frame = frame.copy()\n",
    "\n",
    "        # Apply color thresholding\n",
    "        binary_mask = color_thresholding(frame, lower_bounds, upper_bounds)\n",
    "\n",
    "        # Apply refined circle detection\n",
    "        predicted_mask = refined_circle_detection_with_mask(frame, binary_mask)\n",
    "\n",
    "        # Find the center of the binary mask\n",
    "        center = find_mask_center(predicted_mask)\n",
    "        if center:\n",
    "            all_centers.append(center)\n",
    "\n",
    "        processed_count += 1\n",
    "\n",
    "        # Stop after processing the maximum number of frames\n",
    "        if processed_count >= max_images:\n",
    "            break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Release the video capture\n",
    "video_capture.release()\n",
    "\n",
    "# Process results if a valid first frame exists\n",
    "if first_frame is not None:\n",
    "    # Convert centers to integer coordinates\n",
    "    int_centers = [tuple(map(int, center)) for center in all_centers]\n",
    "\n",
    "    # Find the most left and most right centers\n",
    "    most_left = min(int_centers, key=lambda point: point[0])  # Minimum x-coordinate\n",
    "    most_right = max(int_centers, key=lambda point: point[0])  # Maximum x-coordinate\n",
    "\n",
    "    # Draw a red line between the most left and most right points\n",
    "    cv2.line(first_frame, most_left, most_right, (0, 0, 255), 2)  # Red line\n",
    "\n",
    "    # Show the result\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Swing Motion Indicator (Left to Right)\")\n",
    "    plt.imshow(cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Processed {processed_count} frames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Estimate the AO's Height Above Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Functions for calculations\n",
    "def find_camera_params(size_pixels, size_meters, distance_meters, image_width, image_height):\n",
    "    # Calculate the focal length in pixels\n",
    "    focal_length = (size_pixels * distance_meters) / size_meters\n",
    "    print(f\"Focal length in pixels: {focal_length:.2f}\")\n",
    "\n",
    "    # Assume the camera principal point (cx, cy) is the image center\n",
    "    cx = image_width / 2\n",
    "    cy = image_height / 2\n",
    "\n",
    "    # Intrinsic camera matrix\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, cx],\n",
    "        [0, focal_length, cy],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    return camera_matrix, focal_length\n",
    "\n",
    "def find_real_size(focal_length, size_pixel, distance_meters):\n",
    "    return (size_pixel * distance_meters) / focal_length\n",
    "\n",
    "def find_distance(focal_length, size_pixel, size_real):\n",
    "    return (focal_length * size_real) / size_pixel\n",
    "\n",
    "# Function to perform color thresholding\n",
    "def color_thresholding(image, lower_bounds, upper_bounds):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = np.zeros(hsv_image.shape[:2], dtype=np.uint8)\n",
    "    for lower_bound, upper_bound in zip(lower_bounds, upper_bounds):\n",
    "        mask |= cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    return mask\n",
    "\n",
    "# Function to perform refined circle detection\n",
    "def refined_circle_detection_with_mask(image, color_mask):\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=color_mask)\n",
    "    gray_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (11, 11), 2)\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred_image,\n",
    "        cv2.HOUGH_GRADIENT,\n",
    "        dp=0.2,\n",
    "        minDist=200,\n",
    "        param1=150,\n",
    "        param2=40,\n",
    "        minRadius=30,\n",
    "        maxRadius=400,\n",
    "    )\n",
    "    if circles is not None:\n",
    "        return np.uint16(np.around(circles))[0, 0]  # First circle (x, y, radius)\n",
    "    return None\n",
    "\n",
    "# Inputs\n",
    "image_path = \"2c.jpg\"\n",
    "resize_factor = 0.25  # Resize image to speed up processing\n",
    "\n",
    "focal_length = 5492.23\n",
    "diameter_meters = 7.0\n",
    "distance_of_the_camera_from_floor = 1.80\n",
    "\n",
    "# Lower and upper bounds for color thresholding\n",
    "lower_bounds = [\n",
    "    np.array([10, 0, 0]),  # Example for specific hue\n",
    "    np.array([0, 0, 200])  # Bright whites\n",
    "]\n",
    "upper_bounds = [\n",
    "    np.array([150, 250, 200]),  # Saturated color range\n",
    "    np.array([180, 50, 255])    # Bright whites\n",
    "]\n",
    "\n",
    "# Read and resize the image\n",
    "frame = cv2.imread(image_path)\n",
    "if frame is None:\n",
    "    raise ValueError(\"Unable to read the image.\")\n",
    "height, width, channels = frame.shape\n",
    "frame = cv2.resize(frame, (0, 0), fx=resize_factor, fy=resize_factor)\n",
    "\n",
    "# Apply color thresholding\n",
    "binary_mask = color_thresholding(frame, lower_bounds, upper_bounds)\n",
    "\n",
    "# Apply refined circle detection\n",
    "circle_params = refined_circle_detection_with_mask(frame, binary_mask)\n",
    "if circle_params is None:\n",
    "    raise ValueError(\"No circle detected.\")\n",
    "x, y, r = circle_params  # Center (x, y) and radius\n",
    "\n",
    "# Draw the circle and center\n",
    "output_image = frame.copy()\n",
    "cv2.circle(output_image, (x, y), r, (0, 255, 0), 2)  # Globe circle\n",
    "cv2.circle(output_image, (x, y), 5, (0, 0, 255), -1)  # Center point\n",
    "\n",
    "# Plot horizontal diameter\n",
    "left_x = x - r\n",
    "right_x = x + r\n",
    "cv2.line(output_image, (left_x, y), (right_x, y), (255, 0, 0), 2)  # Diameter line\n",
    "\n",
    "# Calculate and display diameter\n",
    "diameter_pixels = 2 * r\n",
    "print(f\"Diameter in pixels (after resizing): {diameter_pixels}\")\n",
    "\n",
    "# Scale back to original size for correct interpretation\n",
    "original_diameter_pixels = diameter_pixels / resize_factor\n",
    "print(f\"Diameter in pixels (original resolution): {original_diameter_pixels}\")\n",
    "\n",
    "distance_to_globe = find_distance(focal_length, original_diameter_pixels, diameter_meters) + distance_of_the_camera_from_floor\n",
    "print(f\"Distance to globe: {distance_to_globe:.4f} meters\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Globe Detection\\nDistance to globe: {distance_to_globe:.2f} m\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "## Estimate the Rotation Cycle of the AO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Explain Your Methodology\n",
    "### b) Provide a Single Rotation Cycle Estimate as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No code needed here, the explanation is provided in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Continuous Rotation Cycle Estimation from Video\n",
    "### d) Real-Time Rotation Cycle Estimation\n",
    "### e) Compare Estimations from Different Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "video_paths = [\"single_rotation_top_view.mp4\", \"single_rotation_bottom_view.mp4\", \"multiple_rotations_top_view.mp4\"]\n",
    "\n",
    "for video_path in video_paths:\n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"Frame rate: {frame_rate} fps\")\n",
    "    frame_interval = 10  # Process every 10th frame\n",
    "\n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        raise ValueError(\"Unable to read video.\")\n",
    "\n",
    "    # Define ROI (manually set or use a selection tool beforehand)\n",
    "    x, y, w, h = [599, 180, 489, 449]  # Example ROI\n",
    "    if w == 0 or h == 0:\n",
    "        raise ValueError(\"No valid ROI selected.\")\n",
    "\n",
    "    # Extract ROI and detect features in the first frame\n",
    "    first_roi = first_frame[y:y+h, x:x+w]\n",
    "    gray_first_roi = cv2.cvtColor(first_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect features in the first frame using SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(gray_first_roi, None)\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    # Store good matches count for each processed frame\n",
    "    matches_counts = []\n",
    "    processed_frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # End of video stream\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "        # Skip frames to process every 10th frame\n",
    "        if frame_idx % frame_interval != 0:\n",
    "            continue\n",
    "\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        # Extract ROI from the current frame\n",
    "        roi_frame = frame[y:y+h, x:x+w]\n",
    "        gray_roi_frame = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect features in the current frame\n",
    "        kp2, des2 = sift.detectAndCompute(gray_roi_frame, None)\n",
    "        if des2 is None:\n",
    "            matches_counts.append(0)\n",
    "            processed_frames.append(frame_idx)\n",
    "            continue\n",
    "\n",
    "        # Match features using FLANN\n",
    "        index_params = dict(algorithm=1, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Apply Lowe's ratio test\n",
    "        good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "\n",
    "        # Record the number of good matches\n",
    "        matches_counts.append(len(good_matches))\n",
    "        processed_frames.append(frame_idx)\n",
    "\n",
    "        end = time.perf_counter()\n",
    "        elapsed = end - start\n",
    "\n",
    "        print(f\"Frame {frame_idx}: {len(good_matches)} good matches, elapsed: {elapsed:.3f}s\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Convert frame indices to time\n",
    "    processed_times = np.array(processed_frames) / frame_rate\n",
    "\n",
    "    # Find peaks in the matches_counts array\n",
    "    # Adjust parameters as needed (e.g., prominence, height) to reliably find peaks\n",
    "    peaks, _ = find_peaks(matches_counts, prominence=100, distance=50)  # Try different prominence values\n",
    "    peaks = np.insert(peaks, 0, 0.0)\n",
    "\n",
    "    if len(peaks) < 2:\n",
    "        print(\"Not enough peaks found to estimate multiple rotations.\")\n",
    "    else:\n",
    "        \n",
    "        # Calculate rotation periods between consecutive peaks\n",
    "        rotation_times = processed_times[peaks]\n",
    "        intervals = np.diff(rotation_times)  # time differences between peaks\n",
    "\n",
    "        # Number of rotations is basically the number of peaks - 1 (assuming the first peak as the first complete rotation)\n",
    "        num_rotations = len(peaks) - 1\n",
    "        avg_rotation_period = np.mean(intervals) if num_rotations > 0 else None\n",
    "\n",
    "        print(f\"Detected {len(peaks)} peaks at times: {rotation_times}\")\n",
    "        if avg_rotation_period is not None:\n",
    "            print(f\"Number of full rotations: {num_rotations}\")\n",
    "            print(f\"Average rotation period: {avg_rotation_period:.2f} seconds\")\n",
    "        else:\n",
    "            print(\"Only one peak found, cannot compute rotation period.\")\n",
    "\n",
    "    # Plotting the matches over time\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(processed_times, matches_counts, label=f'Number of matches')\n",
    "    if len(peaks) > 0:\n",
    "        plt.plot(processed_times[peaks], np.array(matches_counts)[peaks], 'ro', label='Peaks')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Number of Matches')\n",
    "    plt.title(f'[{video_path}] Number of full rotations: {num_rotations}, Average rotation period: {avg_rotation_period:.2f} seconds')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "# Bonus Objective: Estimate the Landing Speed in the Earth's Coordinate Frame of the Drone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Estimate the AO's Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Functions for calculations\n",
    "def find_camera_params(diameter_pixels, diameter_meters, distance_meters, image_width, image_height):\n",
    "    # Calculate the focal length in pixels\n",
    "    focal_length = (diameter_pixels * distance_meters) / diameter_meters\n",
    "    print(f\"Focal length in pixels: {focal_length:.2f}\")\n",
    "\n",
    "    # Assume the camera principal point (cx, cy) is the image center\n",
    "    cx = image_width / 2\n",
    "    cy = image_height / 2\n",
    "\n",
    "    # Intrinsic camera matrix\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, cx],\n",
    "        [0, focal_length, cy],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    return camera_matrix, focal_length\n",
    "\n",
    "def find_real_size(focal_length, size_pixel, distance_meters):\n",
    "    return (size_pixel * distance_meters) / focal_length\n",
    "\n",
    "def find_distance(focal_length, size_pixel, size_real):\n",
    "    return (focal_length * size_real) / size_pixel\n",
    "\n",
    "# Function to perform color thresholding\n",
    "def color_thresholding(image, lower_bounds, upper_bounds):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = np.zeros(hsv_image.shape[:2], dtype=np.uint8)\n",
    "    for lower_bound, upper_bound in zip(lower_bounds, upper_bounds):\n",
    "        mask |= cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    return mask\n",
    "\n",
    "# Function to perform refined circle detection\n",
    "def refined_circle_detection_with_mask(image, color_mask):\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=color_mask)\n",
    "    gray_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (11, 11), 2)\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred_image,\n",
    "        cv2.HOUGH_GRADIENT,\n",
    "        dp=1.2,\n",
    "        minDist=50,\n",
    "        param1=50,\n",
    "        param2=30,\n",
    "        minRadius=50,\n",
    "        maxRadius=500,\n",
    "    )\n",
    "    if circles is not None:\n",
    "        return np.uint16(np.around(circles))[0, 0]  # First circle (x, y, radius)\n",
    "    return None\n",
    "\n",
    "# Inputs\n",
    "image_path = \"4ab.jpg\"\n",
    "resize_factor = 0.25  # Resize image to speed up processing\n",
    "\n",
    "# Camera matrix and focal length\n",
    "#(array([[1.93142857e+03, 0.00000000e+00, 2.16000000e+03],\n",
    "#        [0.00000000e+00, 1.93142857e+03, 3.84000000e+03],\n",
    "#        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]),\n",
    "# 1931.4285714285713)\n",
    "distance_to_globe = 5.0  # Distance to the globe in meters\n",
    "focal_length = 1931.43\n",
    "\n",
    "# Lower and upper bounds for color thresholding\n",
    "lower_bounds = [\n",
    "    np.array([10, 0, 0]),  # Example for specific hue\n",
    "    np.array([0, 0, 200])  # Bright whites\n",
    "]\n",
    "upper_bounds = [\n",
    "    np.array([150, 250, 200]),  # Saturated color range\n",
    "    np.array([180, 50, 255])    # Bright whites\n",
    "]\n",
    "\n",
    "# Read and resize the image\n",
    "frame = cv2.imread(image_path)\n",
    "if frame is None:\n",
    "    raise ValueError(\"Unable to read the image.\")\n",
    "height, width, channels = frame.shape\n",
    "frame = cv2.resize(frame, (0, 0), fx=resize_factor, fy=resize_factor)\n",
    "\n",
    "# Apply color thresholding\n",
    "binary_mask = color_thresholding(frame, lower_bounds, upper_bounds)\n",
    "\n",
    "# Apply refined circle detection\n",
    "circle_params = refined_circle_detection_with_mask(frame, binary_mask)\n",
    "if circle_params is None:\n",
    "    raise ValueError(\"No circle detected.\")\n",
    "x, y, r = circle_params  # Center (x, y) and radius\n",
    "\n",
    "# Draw the circle and center\n",
    "output_image = frame.copy()\n",
    "cv2.circle(output_image, (x, y), r, (0, 255, 0), 2)  # Globe circle\n",
    "cv2.circle(output_image, (x, y), 5, (0, 0, 255), -1)  # Center point\n",
    "\n",
    "# Plot horizontal diameter\n",
    "left_x = x - r\n",
    "right_x = x + r\n",
    "cv2.line(output_image, (left_x, y), (right_x, y), (255, 0, 0), 2)  # Diameter line\n",
    "\n",
    "# Calculate and display diameter\n",
    "diameter_pixels = 2 * r\n",
    "print(f\"Diameter in pixels (after resizing): {diameter_pixels}\")\n",
    "\n",
    "# Scale back to original size for correct interpretation\n",
    "original_diameter_pixels = diameter_pixels / resize_factor\n",
    "print(f\"Diameter in pixels (original resolution): {original_diameter_pixels}\")\n",
    "\n",
    "# Calculate real size (validation)\n",
    "real_diameter_calculated = find_real_size(focal_length, original_diameter_pixels, distance_to_globe)\n",
    "print(f\"Real diameter calculated: {real_diameter_calculated:.4f} meters\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Globe Detection\\nDiameter: {real_diameter_calculated:.2f} m\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Evaluate Radius Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Functions for calculations\n",
    "def find_real_size(focal_length, size_pixel, distance_meters):\n",
    "    return (size_pixel * distance_meters) / focal_length\n",
    "\n",
    "# Function to perform color thresholding\n",
    "def color_thresholding(image, lower_bounds, upper_bounds):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = np.zeros(hsv_image.shape[:2], dtype=np.uint8)\n",
    "    for lower_bound, upper_bound in zip(lower_bounds, upper_bounds):\n",
    "        mask |= cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    return mask\n",
    "\n",
    "# Refined circle detection to create a mask\n",
    "def refined_circle_detection_with_mask(image, color_mask):\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=color_mask)\n",
    "    gray_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (9, 9), 2)\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred_image,\n",
    "        cv2.HOUGH_GRADIENT,\n",
    "        dp=0.2,\n",
    "        minDist=200,\n",
    "        param1=150,\n",
    "        param2=40,\n",
    "        minRadius=30,\n",
    "        maxRadius=400,\n",
    "    )\n",
    "    mask = np.zeros_like(gray_image)\n",
    "    if circles is not None:\n",
    "        circle = np.round(circles[0, 0]).astype(\"int\")\n",
    "        x, y, r = circle\n",
    "        cv2.circle(mask, (x, y), r, 255, -1)\n",
    "    return mask\n",
    "\n",
    "# Find center and radii based on the mask\n",
    "def find_mask_center_and_radii(mask):\n",
    "    white_pixels = np.column_stack(np.where(mask == 255))\n",
    "    if len(white_pixels) == 0:\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    # Find center\n",
    "    center_y, center_x = white_pixels.mean(axis=0)\n",
    "    center_x, center_y = int(center_x), int(center_y)\n",
    "\n",
    "    # Compute radii\n",
    "    # Left and right\n",
    "    row_pixels = np.where(mask[center_y, :] == 255)[0]\n",
    "    left_radius = center_x - row_pixels[0]\n",
    "    right_radius = row_pixels[-1] - center_x\n",
    "\n",
    "    # Top and bottom\n",
    "    col_pixels = np.where(mask[:, center_x] == 255)[0]\n",
    "    top_radius = center_y - col_pixels[0]\n",
    "    bottom_radius = col_pixels[-1] - center_y\n",
    "\n",
    "    return center_x, center_y, left_radius, right_radius, top_radius, bottom_radius\n",
    "\n",
    "# Inputs\n",
    "image_path = \"4ab.jpg\"\n",
    "resize_factor = 0.25  # Resize image for performance\n",
    "distance_to_globe = 5.0  # Distance to the globe in meters\n",
    "focal_length = 1931.43  # Focal length in pixels\n",
    "\n",
    "# Lower and upper bounds for color thresholding\n",
    "lower_bounds = [\n",
    "    np.array([10, 0, 0]),\n",
    "    np.array([0, 0, 200])\n",
    "]\n",
    "upper_bounds = [\n",
    "    np.array([150, 250, 200]),\n",
    "    np.array([180, 50, 255])\n",
    "]\n",
    "\n",
    "# Read and resize the image\n",
    "frame = cv2.imread(image_path)\n",
    "if frame is None:\n",
    "    raise ValueError(\"Unable to read the image.\")\n",
    "height, width, channels = frame.shape\n",
    "frame = cv2.resize(frame, (0, 0), fx=resize_factor, fy=resize_factor)\n",
    "\n",
    "# Apply color thresholding and refined circle detection\n",
    "binary_mask = color_thresholding(frame, lower_bounds, upper_bounds)\n",
    "circle_mask = refined_circle_detection_with_mask(frame, binary_mask)\n",
    "\n",
    "# Find center and radii\n",
    "center_x, center_y, left_radius, right_radius, top_radius, bottom_radius = find_mask_center_and_radii(circle_mask)\n",
    "if center_x is None:\n",
    "    raise ValueError(\"No valid mask or radii found.\")\n",
    "\n",
    "# Convert radii to real-world meters\n",
    "real_radius_left = find_real_size(focal_length, left_radius // resize_factor, distance_to_globe)\n",
    "real_radius_right = find_real_size(focal_length, right_radius // resize_factor, distance_to_globe)\n",
    "real_radius_top = find_real_size(focal_length, top_radius // resize_factor, distance_to_globe)\n",
    "real_radius_bottom = find_real_size(focal_length, bottom_radius // resize_factor, distance_to_globe)\n",
    "\n",
    "# Check uniformity of radii\n",
    "radii = [real_radius_left, real_radius_right, real_radius_top, real_radius_bottom]\n",
    "uniform = max(radii) - min(radii) < 0.01  # Uniform if difference < 1cm\n",
    "ratios = [radius / max(radii) for radius in radii]\n",
    "\n",
    "# Draw visualization\n",
    "output_image = frame.copy()\n",
    "#cv2.circle(output_image, (center_x, center_y), left_radius, (0, 255, 0), 2)\n",
    "#cv2.circle(output_image, (center_x, center_y), 5, (0, 0, 255), -1)\n",
    "cv2.line(output_image, (center_x - left_radius, center_y), (center_x + right_radius, center_y), (255, 0, 0), 2)\n",
    "cv2.line(output_image, (center_x, center_y - top_radius), (center_x, center_y + bottom_radius), (255, 0, 0), 2)\n",
    "\n",
    "# Display results\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\n",
    "    f\"Radii: Left={real_radius_left:.2f}m, Right={real_radius_right:.2f}m\\n\"\n",
    "    f\"Top={real_radius_top:.2f}m, Bottom={real_radius_bottom:.2f}m\\n\"\n",
    "    f\"Uniform: {'Yes' if uniform else 'No'}\\n\"\n",
    "    f\"Ratios: L={ratios[0]:.2f}, R={ratios[1]:.2f}, T={ratios[2]:.2f}, B={ratios[3]:.2f}\"\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Calculate Surface Linear Velocity\n",
    "### d) Real-Time Velocity Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "\n",
    "# Hardcoded ROI\n",
    "x, y, w, h = 618, 220, 444, 386  # ROI coordinates\n",
    "\n",
    "video_path = 'single_rotation_top_view.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps == 0:\n",
    "    raise ValueError(\"FPS could not be retrieved. Check the video file.\")\n",
    "frame_time = 1 / fps\n",
    "\n",
    "# Process only the first 30 seconds\n",
    "max_duration = 360  # seconds\n",
    "max_frames = int(fps * max_duration)\n",
    "\n",
    "# Rotation constants\n",
    "rotation_period = 326  # 5 minutes 26 seconds (in seconds)\n",
    "angular_velocity = 2 * np.pi / rotation_period  # Angular velocity (radians/second)\n",
    "\n",
    "# Detect globe in the first frame\n",
    "ret, first_frame = cap.read()\n",
    "if not ret:\n",
    "    raise ValueError(\"Unable to read video.\")\n",
    "gray_first = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Extract ROI from the first frame\n",
    "roi_first = gray_first[y:y+h, x:x+w]\n",
    "\n",
    "# Detect the globe using Hough Circles\n",
    "circles = cv2.HoughCircles(\n",
    "    roi_first,\n",
    "    cv2.HOUGH_GRADIENT,\n",
    "    dp=1.2,\n",
    "    minDist=50,\n",
    "    param1=50,\n",
    "    param2=30,\n",
    "    minRadius=100,\n",
    "    maxRadius=250,\n",
    ")\n",
    "\n",
    "if circles is None:\n",
    "    raise ValueError(\"No globe detected within the ROI.\")\n",
    "circles = np.uint16(np.around(circles))[0, 0]  # Take the first detected circle\n",
    "circle_center = (circles[0], circles[1])  # (x, y) center of the circle\n",
    "circle_radius = circles[2]  # Radius of the globe\n",
    "\n",
    "# Create a circular mask for the globe\n",
    "mask = np.zeros_like(roi_first, dtype=np.uint8)\n",
    "cv2.circle(mask, circle_center, circle_radius, 255, -1)\n",
    "\n",
    "# Use SIFT for feature detection within the mask (only in the first frame)\n",
    "sift = cv2.SIFT_create(nfeatures=5000)\n",
    "kp = sift.detect(roi_first, mask)\n",
    "if len(kp) == 0:\n",
    "    raise ValueError(\"No features detected within the globe mask.\")\n",
    "\n",
    "# Convert keypoints to numpy array of shape (N, 2), adjusting to global coords\n",
    "features = np.array([kp_.pt for kp_ in kp], dtype=np.float32)\n",
    "features_global = features.copy()\n",
    "features_global[:, 0] += x\n",
    "features_global[:, 1] += y\n",
    "\n",
    "# Enforce maximum number of tracked features\n",
    "max_features = 100  # Limit for maximum tracked features\n",
    "if len(features_global) > max_features:\n",
    "    features_global = features_global[np.random.choice(len(features_global), max_features, replace=False)]\n",
    "\n",
    "# Ensure all selected features are inside the circular mask\n",
    "distances = np.linalg.norm(features_global - np.array([x + circle_center[0], y + circle_center[1]]), axis=1)\n",
    "features_global = features_global[distances <= circle_radius]\n",
    "\n",
    "# Initialize tracking\n",
    "all_positions = [features_global]\n",
    "prev_gray = gray_first\n",
    "frame_count = 0\n",
    "\n",
    "# Precompute velocity map using the mask radius\n",
    "grid_size_x, grid_size_y = 50, 50  # Grid resolution\n",
    "velocity_map = np.zeros((grid_size_y, grid_size_x))  # Initialize velocity map\n",
    "\n",
    "# Calculate tangential velocity for each grid cell\n",
    "y_center = grid_size_y // 2  # Vertical center of the grid (equator)\n",
    "for j in range(grid_size_y):\n",
    "    for i in range(grid_size_x):\n",
    "        relative_y = (j - y_center) / (grid_size_y // 2)  # Normalized latitude\n",
    "        if abs(relative_y) <= 1.0:\n",
    "            latitude = np.arcsin(relative_y)\n",
    "            velocity_map[j, i] = angular_velocity * circle_radius * np.cos(latitude)  # Tangential velocity\n",
    "        else:\n",
    "            velocity_map[j, i] = 0  # Outside the circle\n",
    "\n",
    "# Plot the velocity map\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(velocity_map, cmap='jet', extent=(0, grid_size_x, grid_size_y, 0), norm=Normalize())\n",
    "plt.colorbar(label=\"Velocity (pixels/s)\")\n",
    "plt.title(\"Expected Tangential Velocity Distribution\")\n",
    "plt.xlabel(\"X (pixels)\")\n",
    "plt.ylabel(\"Y (pixels)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Normalize velocity map for color mapping\n",
    "norm = Normalize(vmin=velocity_map.min(), vmax=velocity_map.max())\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count > max_frames:\n",
    "        # Stop after 30 seconds\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Track features using optical flow\n",
    "    p0 = all_positions[-1].astype(np.float32)\n",
    "    # Convert p0 to ROI coords for optical flow\n",
    "    p0_roi = p0.copy()\n",
    "    p0_roi[:, 0] -= x\n",
    "    p0_roi[:, 1] -= y\n",
    "\n",
    "    new_features, status, _ = cv2.calcOpticalFlowPyrLK(\n",
    "        prev_gray[y:y+h, x:x+w],\n",
    "        gray[y:y+h, x:x+w],\n",
    "        p0_roi,\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if new_features is None:\n",
    "        # No new features tracked\n",
    "        break\n",
    "\n",
    "    valid_new_roi = new_features[status.flatten() == 1]\n",
    "    valid_old_roi = p0_roi[status.flatten() == 1]\n",
    "\n",
    "    # Convert back to global coords\n",
    "    valid_new = np.zeros_like(valid_new_roi)\n",
    "    valid_new[:, 0] = valid_new_roi[:, 0] + x\n",
    "    valid_new[:, 1] = valid_new_roi[:, 1] + y\n",
    "\n",
    "    # Draw the points with colors based on their velocity from the velocity map\n",
    "    display_frame = frame.copy()\n",
    "    for new in valid_new_roi:\n",
    "        grid_x = int(new[0] / (w / grid_size_x))\n",
    "        grid_y = int(new[1] / (h / grid_size_y))\n",
    "        if 0 <= grid_x < grid_size_x and 0 <= grid_y < grid_size_y:\n",
    "            velocity = velocity_map[grid_y, grid_x]\n",
    "            color = cm.jet(norm(velocity))[:3]  # Normalize velocity to color map\n",
    "            color_bgr = tuple(int(c * 255) for c in color[::-1])  # Convert to BGR\n",
    "            x_new, y_new = int(new[0] + x), int(new[1] + y)\n",
    "            cv2.circle(display_frame, (x_new, y_new), 3, color_bgr, -1)\n",
    "            cv2.putText(display_frame, f\"{velocity:.1f} px/s\", (x_new + 5, y_new - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
    "\n",
    "    # Draw detected globe\n",
    "    #cv2.circle(display_frame[y:y+h, x:x+w], circle_center, circle_radius, (255, 0, 0), 2)\n",
    "\n",
    "    # Show the video with tracked points and colors\n",
    "    cv2.imshow('Video with Tracked Points', display_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Update for next iteration\n",
    "    prev_gray = gray\n",
    "    all_positions.append(valid_new)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0241",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
